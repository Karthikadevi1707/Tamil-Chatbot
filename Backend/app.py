from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from groq import Groq
import base64
from PyPDF2 import PdfReader
from io import BytesIO
import os
from dotenv import load_dotenv

print("ЁЯФе Tamil AI Backend Running ЁЯФе")

##GROQ_API_KEY = "REMOVED_GROQ_KEY"
##client = Groq(api_key=GROQ_API_KEY)

load_dotenv()

class Settings:
    GROQ_API_KEY: str = os.getenv("GROQ_API_KEY")
    MODEL_NAME: str = os.getenv("MODEL_NAME")

settings = Settings()
print("Loaded GROQ API KEY:", settings.GROQ_API_KEY)


client = Groq(api_key=os.getenv("GROQ_API_KEY"))
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# -----------------------------
# MODELS
TEXT_MODEL = "meta-llama/llama-4-maverick-17b-128e-instruct"
VISION_MODEL = "meta-llama/llama-4-scout-17b-16e-instruct"
# -----------------------------

class QuestionRequest(BaseModel):
    question: str

class ImagePrompt(BaseModel):
    prompt: str


@app.get("/")
def home():
    return {"status": "Backend Running ЁЯЪА"}


# ЁЯФ╣ TEXT
@app.post("/ask")
def ask_question(data: QuestionRequest):
    try:
        response = client.chat.completions.create(
            model=TEXT_MODEL,
            messages=[
                {
                    "role": "system",
                    "content": """
                    роирпАроЩрпНроХро│рпН родрооро┐ро┤рпН роЗро▓роХрпНроХро┐роп рокрпЗро░ро╛роЪро┐ро░ро┐ропро░рпН.
                    ро╡ро┐ро░ро┐ро╡ро╛роХро╡рпБроорпН родрпБрогрпИродрпН родро▓рпИрокрпНрокрпБроХро│рпБроЯройрпН рокродро┐ро▓рпН роЕро│ро┐роХрпНроХро╡рпБроорпН.
                    """
                },
                {"role": "user", "content": data.question}
            ],
            temperature=0.7,
            max_tokens=1500
        )

        return {"answer": response.choices[0].message.content}

    except Exception as e:
        return {"answer": f"Server Error: {str(e)}"}


# ЁЯФ╣ IMAGE UNDERSTANDING
@app.post("/image-question")
async def image_question(file: UploadFile = File(...)):
    try:
        image_bytes = await file.read()
        base64_image = base64.b64encode(image_bytes).decode("utf-8")

        response = client.chat.completions.create(
            model=VISION_MODEL,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text",
                         "text": "роЗроирпНрод рокроЯродрпНродро┐ро▓рпН роЙро│рпНро│родрпИ ро╡ро┐ро╡ро░рооро╛роХ родрооро┐ро┤ро┐ро▓рпН ро╡ро┐ро│роХрпНроХро╡рпБроорпН."},
                        {"type": "image_url",
                         "image_url": {
                             "url": f"data:image/jpeg;base64,{base64_image}"
                         }}
                    ]
                }
            ],
            max_tokens=1500
        )

        return {"answer": response.choices[0].message.content}

    except Exception as e:
        return {"answer": f"Image Server Error: {str(e)}"}


# ЁЯФ╣ PDF
@app.post("/pdf-question")
async def pdf_question(file: UploadFile = File(...)):
    try:
        pdf_bytes = await file.read()
        reader = PdfReader(BytesIO(pdf_bytes))

        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"

        response = client.chat.completions.create(
            model=TEXT_MODEL,
            messages=[
                {"role": "system",
                 "content": "PDF роЙро│рпНро│роЯроХрпНроХродрпНродрпИ роЕроЯро┐рокрпНрокроЯрпИропро╛роХ роХрпКрогрпНроЯрпБ родрооро┐ро┤ро┐ро▓рпН ро╡ро┐ро│роХрпНроХро╡рпБроорпН."},
                {"role": "user", "content": text[:12000]}
            ],
            max_tokens=1500
        )

        return {"answer": response.choices[0].message.content}

    except Exception as e:
        return {"answer": f"PDF Error: {str(e)}"}


# ЁЯФ╣ IMAGE GENERATION (Prompt тЖТ Creative Description)
@app.post("/generate-image")
def generate_image(data: ImagePrompt):
    try:
        response = client.chat.completions.create(
            model=TEXT_MODEL,
            messages=[
                {
                    "role": "system",
                    "content": """
                    рокропройро░рпН роХрпКроЯрпБродрпНрод prompt роЕроЯро┐рокрпНрокроЯрпИропро┐ро▓рпН
                    роТро░рпБ рооро┐роХ роЕро┤роХро╛рой роХро╛роЯрпНроЪро┐ропрпИ ро╡ро┐ро░ро┐ро╡ро╛роХ ро╡ро┐ро╡ро░ро┐роХрпНроХро╡рпБроорпН.
                    (Image generation style description)
                    """
                },
                {"role": "user", "content": data.prompt}
            ],
            max_tokens=1000
        )

        description = response.choices[0].message.content

        return {"image_description": description}

    except Exception as e:
        return {"error": str(e)}